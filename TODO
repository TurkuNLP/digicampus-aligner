1) Test with real data
- [done] remove the document itself as the return
- if there are a larger number of documents (e.g. 40+), quite often one query doesn't work, have to switch to another and then switch back for it to work, or click multiple times
- would be nice to show the document IDs for the returned documents
- if query by text, switch to query by document, text has to be manually removed
- sentence segmentation: 'mm.' got broken down into two sentences
- observation: high precision, low recall

2) I think it would be good to try with euclidean distance but maybe it's not necessary

3) API needs to be documented

4) Document similarity matrix (doc_sim_matrix_tfidf and/or margin_doc_sim) should be exposed in the API

   The structure returned by query_by_doc_id and query_tfidf should be exposed as json

5) Segmentation would be good to return in terms of character offsets (needs back-align to source text after udpipe)

6) udpipe is not thread-safe, some solution is missing

7) calls in API should be wrapped into try .. except so the application does not die on bad input

...

